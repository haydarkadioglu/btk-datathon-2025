{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T12:15:36.337019Z",
     "iopub.status.busy": "2025-08-29T12:15:36.336680Z",
     "iopub.status.idle": "2025-08-29T12:15:37.248944Z",
     "shell.execute_reply": "2025-08-29T12:15:37.248050Z",
     "shell.execute_reply.started": "2025-08-29T12:15:36.336993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "\n",
    "# Train verisi\n",
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# datetime özellikleri\n",
    "train[\"event_time\"] = pd.to_datetime(train[\"event_time\"])\n",
    "train[\"hour\"] = train[\"event_time\"].dt.hour\n",
    "train[\"dayofweek\"] = train[\"event_time\"].dt.dayofweek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T12:15:40.234477Z",
     "iopub.status.busy": "2025-08-29T12:15:40.234084Z",
     "iopub.status.idle": "2025-08-29T12:16:41.589034Z",
     "shell.execute_reply": "2025-08-29T12:16:41.588235Z",
     "shell.execute_reply.started": "2025-08-29T12:15:40.234446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "def build_session_features_advanced(df, with_target=False):\n",
    "    session_feats = df.groupby(\"user_session\").agg(\n",
    "        event_count=(\"event_type\", \"count\"),\n",
    "        unique_products=(\"product_id\", \"nunique\"),\n",
    "        unique_categories=(\"category_id\", \"nunique\"),\n",
    "        unique_event_types=(\"event_type\", \"nunique\"),\n",
    "        avg_hour=(\"hour\", \"mean\"),\n",
    "        dayofweek_mode=(\"dayofweek\", lambda x: x.mode().iloc[0] if not x.mode().empty else -1),\n",
    "    ).reset_index()\n",
    "\n",
    "    df_time = df[[\"user_session\", \"event_time\"]].copy()\n",
    "    df_time[\"event_time\"] = pd.to_datetime(df_time[\"event_time\"])\n",
    "    session_length = df_time.groupby(\"user_session\").agg(\n",
    "        session_length=(\"event_time\", lambda x: (x.max() - x.min()).total_seconds())\n",
    "    ).reset_index()\n",
    "    session_feats = session_feats.merge(session_length, on=\"user_session\", how=\"left\")\n",
    "\n",
    "    event_counts = df.groupby([\"user_session\", \"event_type\"]).size().unstack(fill_value=0).reset_index()\n",
    "    session_feats = session_feats.merge(event_counts, on=\"user_session\", how=\"left\")\n",
    "\n",
    "    for ev in [\"ADD_CART\", \"VIEW\", \"REMOVE_CART\", \"PURCHASE\"]:\n",
    "        if ev in session_feats.columns:\n",
    "            session_feats[f\"ratio_{ev}\"] = session_feats[ev] / session_feats[\"event_count\"]\n",
    "\n",
    "    session_feats[\"product_diversity\"] = session_feats[\"unique_products\"] / session_feats[\"event_count\"]\n",
    "    session_feats[\"category_diversity\"] = session_feats[\"unique_categories\"] / session_feats[\"event_count\"]\n",
    "\n",
    "    # Ek özellikler\n",
    "    session_feats[\"session_length_log\"] = np.log1p(session_feats[\"session_length\"])\n",
    "    session_feats[\"view_per_product\"] = session_feats.get(\"VIEW\", 0) / session_feats[\"unique_products\"]\n",
    "    session_feats[\"addcart_per_product\"] = session_feats.get(\"ADD_CART\", 0) / session_feats[\"unique_products\"]\n",
    "    session_feats[\"purchase_per_product\"] = session_feats.get(\"PURCHASE\", 0) / session_feats[\"unique_products\"]\n",
    "    session_feats[\"category_per_product\"] = session_feats[\"unique_categories\"] / session_feats[\"unique_products\"]\n",
    "    session_feats[\"events_per_unique_product\"] = session_feats[\"event_count\"] / session_feats[\"unique_products\"]\n",
    "\n",
    "    # Cyclical encoding\n",
    "    session_feats[\"hour_sin\"] = np.sin(2 * np.pi * session_feats[\"avg_hour\"] / 24)\n",
    "    session_feats[\"hour_cos\"] = np.cos(2 * np.pi * session_feats[\"avg_hour\"] / 24)\n",
    "    session_feats[\"dayofweek_sin\"] = np.sin(2 * np.pi * session_feats[\"dayofweek_mode\"] / 7)\n",
    "    session_feats[\"dayofweek_cos\"] = np.cos(2 * np.pi * session_feats[\"dayofweek_mode\"] / 7)\n",
    "\n",
    "    # Numeric encoding\n",
    "    for col in [\"product_id\", \"category_id\", \"user_id\"]:\n",
    "        if df[col].dtype.name != \"category\":\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "        session_stats = df.groupby(\"user_session\")[col].apply(lambda x: x.cat.codes.mean()).reset_index(name=f\"{col}_mean_code\")\n",
    "        session_feats = session_feats.merge(session_stats, on=\"user_session\", how=\"left\")\n",
    "\n",
    "    if with_target and \"session_value\" in df.columns:\n",
    "        target = df.groupby(\"user_session\")[\"session_value\"].first().reset_index()\n",
    "        session_feats = session_feats.merge(target, on=\"user_session\", how=\"left\")\n",
    "\n",
    "    return session_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = build_session_features_advanced(train, with_target=True)\n",
    "\n",
    "# Target ve feature ayır\n",
    "X = train_features.drop([\"user_session\", \"session_value\"], axis=1)\n",
    "y = train_features[\"session_value\"]\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.values.astype(np.float32)\n",
    "y_train_np = y_train.values.astype(np.float32).reshape(-1,1)\n",
    "X_val_np = X_val.values.astype(np.float32)\n",
    "y_val_np = y_val.values.astype(np.float32).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Hiperparametreleri seç\n",
    "    n_d = trial.suggest_int(\"n_d\", 8, 64, step=8)\n",
    "    n_a = trial.suggest_int(\"n_a\", 8, 64, step=8)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 3, 10)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1.0, 2.0, step=0.1)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
    "    \n",
    "    model = TabNetRegressor(\n",
    "        n_d=n_d,\n",
    "        n_a=n_a,\n",
    "        n_steps=n_steps,\n",
    "        gamma=gamma,\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=lr),\n",
    "        mask_type=\"entmax\"\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_np, y_train_np,\n",
    "        eval_set=[(X_val_np, y_val_np)],\n",
    "        max_epochs=50,\n",
    "        patience=5,\n",
    "        batch_size=1024,\n",
    "        virtual_batch_size=128\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_val_np)\n",
    "    mse = mean_squared_error(y_val_np, y_pred)\n",
    "    \n",
    "    # En iyi modeli kaydet\n",
    "    if trial.should_prune() is False:  # erken durdurma yoksa\n",
    "        model_file = \"best_tabnet_model.pkl\"\n",
    "        joblib.dump(model, model_file)\n",
    "    \n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-29 17:13:53,620] A new study created in memory with name: no-name-1872b255-10e1-4ef3-8493-d176674768bf\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1790.78635| val_0_mse: 1044.01331|  0:00:03s\n",
      "epoch 1  | loss: 649.67198| val_0_mse: 521.06427|  0:00:06s\n",
      "epoch 2  | loss: 552.91056| val_0_mse: 479.4772|  0:00:10s\n",
      "epoch 3  | loss: 508.01678| val_0_mse: 683.4433|  0:00:13s\n",
      "epoch 4  | loss: 506.38059| val_0_mse: 564.72656|  0:00:16s\n",
      "epoch 5  | loss: 491.78307| val_0_mse: 580.76422|  0:00:19s\n",
      "epoch 6  | loss: 483.03268| val_0_mse: 544.99518|  0:00:23s\n",
      "epoch 7  | loss: 480.13712| val_0_mse: 503.77475|  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 7 with best_epoch = 2 and best_val_0_mse = 479.4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:14:22,180] Trial 0 finished with value: 479.4772033691406 and parameters: {'n_d': 8, 'n_a': 24, 'n_steps': 4, 'gamma': 2.0, 'lr': 0.030751288603550666}. Best is trial 0 with value: 479.4772033691406.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2901.95853| val_0_mse: 2120.11279|  0:00:05s\n",
      "epoch 1  | loss: 1276.46697| val_0_mse: 870.17035|  0:00:10s\n",
      "epoch 2  | loss: 689.76253| val_0_mse: 666.56421|  0:00:15s\n",
      "epoch 3  | loss: 627.84015| val_0_mse: 655.91351|  0:00:20s\n",
      "epoch 4  | loss: 562.72998| val_0_mse: 573.65747|  0:00:26s\n",
      "epoch 5  | loss: 523.99524| val_0_mse: 632.66846|  0:00:31s\n",
      "epoch 6  | loss: 512.86494| val_0_mse: 541.03943|  0:00:37s\n",
      "epoch 7  | loss: 509.70938| val_0_mse: 532.81689|  0:00:42s\n",
      "epoch 8  | loss: 505.06284| val_0_mse: 534.38971|  0:00:48s\n",
      "epoch 9  | loss: 463.88042| val_0_mse: 518.29297|  0:00:53s\n",
      "epoch 10 | loss: 444.86708| val_0_mse: 497.47159|  0:00:58s\n",
      "epoch 11 | loss: 434.53926| val_0_mse: 526.62292|  0:01:04s\n",
      "epoch 12 | loss: 429.61026| val_0_mse: 558.49792|  0:01:09s\n",
      "epoch 13 | loss: 427.66411| val_0_mse: 492.32916|  0:01:14s\n",
      "epoch 14 | loss: 404.89076| val_0_mse: 469.72089|  0:01:20s\n",
      "epoch 15 | loss: 416.18099| val_0_mse: 420.60779|  0:01:25s\n",
      "epoch 16 | loss: 400.65414| val_0_mse: 508.47415|  0:01:30s\n",
      "epoch 17 | loss: 408.12815| val_0_mse: 428.21686|  0:01:36s\n",
      "epoch 18 | loss: 400.23324| val_0_mse: 544.073 |  0:01:41s\n",
      "epoch 19 | loss: 395.33108| val_0_mse: 453.43506|  0:01:47s\n",
      "epoch 20 | loss: 383.15602| val_0_mse: 537.75702|  0:01:52s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_0_mse = 420.60779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:16:17,555] Trial 1 finished with value: 420.6077880859375 and parameters: {'n_d': 48, 'n_a': 64, 'n_steps': 4, 'gamma': 1.9, 'lr': 0.0029818584804036387}. Best is trial 1 with value: 420.6077880859375.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2712.99678| val_0_mse: 2134.34009|  0:00:09s\n",
      "epoch 1  | loss: 1484.11038| val_0_mse: 1255.75574|  0:00:19s\n",
      "epoch 2  | loss: 1139.20754| val_0_mse: 1125.15881|  0:00:29s\n",
      "epoch 3  | loss: 990.67197| val_0_mse: 921.35339|  0:00:38s\n",
      "epoch 4  | loss: 827.65349| val_0_mse: 934.26776|  0:00:48s\n",
      "epoch 5  | loss: 812.75959| val_0_mse: 840.93988|  0:00:57s\n",
      "epoch 6  | loss: 774.36834| val_0_mse: 785.14258|  0:01:07s\n",
      "epoch 7  | loss: 781.7807| val_0_mse: 707.28387|  0:01:16s\n",
      "epoch 8  | loss: 733.77141| val_0_mse: 619.86188|  0:01:26s\n",
      "epoch 9  | loss: 752.08184| val_0_mse: 834.55286|  0:01:36s\n",
      "epoch 10 | loss: 699.77913| val_0_mse: 599.01459|  0:01:46s\n",
      "epoch 11 | loss: 657.70363| val_0_mse: 681.47076|  0:01:55s\n",
      "epoch 12 | loss: 635.96892| val_0_mse: 631.20538|  0:02:05s\n",
      "epoch 13 | loss: 620.15437| val_0_mse: 684.87354|  0:02:14s\n",
      "epoch 14 | loss: 623.46517| val_0_mse: 669.60895|  0:02:25s\n",
      "epoch 15 | loss: 611.61349| val_0_mse: 728.20099|  0:02:35s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 10 and best_val_0_mse = 599.01459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:18:58,949] Trial 2 finished with value: 599.0145874023438 and parameters: {'n_d': 24, 'n_a': 48, 'n_steps': 10, 'gamma': 1.8, 'lr': 0.006049599517116218}. Best is trial 1 with value: 420.6077880859375.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3319.61921| val_0_mse: 2918.97144|  0:00:04s\n",
      "epoch 1  | loss: 2061.35859| val_0_mse: 1646.88696|  0:00:08s\n",
      "epoch 2  | loss: 1046.99975| val_0_mse: 755.64069|  0:00:13s\n",
      "epoch 3  | loss: 633.74363| val_0_mse: 502.7005|  0:00:17s\n",
      "epoch 4  | loss: 581.32579| val_0_mse: 556.56311|  0:00:21s\n",
      "epoch 5  | loss: 545.72601| val_0_mse: 515.34607|  0:00:26s\n",
      "epoch 6  | loss: 502.16612| val_0_mse: 491.61127|  0:00:30s\n",
      "epoch 7  | loss: 475.75247| val_0_mse: 456.46368|  0:00:35s\n",
      "epoch 8  | loss: 464.05849| val_0_mse: 483.94962|  0:00:39s\n",
      "epoch 9  | loss: 496.72157| val_0_mse: 512.54688|  0:00:43s\n",
      "epoch 10 | loss: 460.43807| val_0_mse: 508.5849|  0:00:48s\n",
      "epoch 11 | loss: 446.62415| val_0_mse: 453.79166|  0:00:52s\n",
      "epoch 12 | loss: 445.57496| val_0_mse: 492.1514|  0:00:56s\n",
      "epoch 13 | loss: 460.2082| val_0_mse: 469.97437|  0:01:00s\n",
      "epoch 14 | loss: 453.4211| val_0_mse: 531.10345|  0:01:04s\n",
      "epoch 15 | loss: 430.00164| val_0_mse: 549.00171|  0:01:08s\n",
      "epoch 16 | loss: 416.38838| val_0_mse: 496.24979|  0:01:13s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_0_mse = 453.79166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:20:14,968] Trial 3 finished with value: 453.7916564941406 and parameters: {'n_d': 16, 'n_a': 40, 'n_steps': 4, 'gamma': 1.3, 'lr': 0.0030925088079636048}. Best is trial 1 with value: 420.6077880859375.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2641.17342| val_0_mse: 1569.85242|  0:00:07s\n",
      "epoch 1  | loss: 908.29973| val_0_mse: 892.08624|  0:00:14s\n",
      "epoch 2  | loss: 696.6699| val_0_mse: 759.92834|  0:00:21s\n",
      "epoch 3  | loss: 630.85185| val_0_mse: 580.91425|  0:00:28s\n",
      "epoch 4  | loss: 585.44025| val_0_mse: 726.37567|  0:00:36s\n",
      "epoch 5  | loss: 556.20598| val_0_mse: 579.67114|  0:00:43s\n",
      "epoch 6  | loss: 594.11926| val_0_mse: 526.78314|  0:00:51s\n",
      "epoch 7  | loss: 517.95054| val_0_mse: 529.85742|  0:00:59s\n",
      "epoch 8  | loss: 531.69793| val_0_mse: 482.97061|  0:01:06s\n",
      "epoch 9  | loss: 504.85487| val_0_mse: 495.41684|  0:01:13s\n",
      "epoch 10 | loss: 516.03353| val_0_mse: 543.86853|  0:01:20s\n",
      "epoch 11 | loss: 478.17177| val_0_mse: 415.96262|  0:01:27s\n",
      "epoch 12 | loss: 481.69203| val_0_mse: 464.68689|  0:01:34s\n",
      "epoch 13 | loss: 463.68376| val_0_mse: 490.76569|  0:01:41s\n",
      "epoch 14 | loss: 459.72316| val_0_mse: 463.37753|  0:01:49s\n",
      "epoch 15 | loss: 462.52384| val_0_mse: 473.70029|  0:01:56s\n",
      "epoch 16 | loss: 454.95279| val_0_mse: 531.04407|  0:02:03s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_0_mse = 415.96262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:22:23,112] Trial 4 finished with value: 415.9626159667969 and parameters: {'n_d': 48, 'n_a': 40, 'n_steps': 6, 'gamma': 1.3, 'lr': 0.005334236371651948}. Best is trial 4 with value: 415.9626159667969.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1136.19561| val_0_mse: 842.11029|  0:00:09s\n",
      "epoch 1  | loss: 598.76859| val_0_mse: 579.39905|  0:00:18s\n",
      "epoch 2  | loss: 532.4558| val_0_mse: 492.83496|  0:00:27s\n",
      "epoch 3  | loss: 518.65778| val_0_mse: 495.59665|  0:00:36s\n",
      "epoch 4  | loss: 464.97738| val_0_mse: 452.46786|  0:00:45s\n",
      "epoch 5  | loss: 487.67376| val_0_mse: 522.12622|  0:00:55s\n",
      "epoch 6  | loss: 464.49704| val_0_mse: 429.05649|  0:01:04s\n",
      "epoch 7  | loss: 442.34169| val_0_mse: 448.15506|  0:01:13s\n",
      "epoch 8  | loss: 431.84835| val_0_mse: 427.11682|  0:01:23s\n",
      "epoch 9  | loss: 401.13669| val_0_mse: 400.03741|  0:01:32s\n",
      "epoch 10 | loss: 393.39691| val_0_mse: 431.21262|  0:01:41s\n",
      "epoch 11 | loss: 405.56665| val_0_mse: 399.2937|  0:01:50s\n",
      "epoch 12 | loss: 380.7987| val_0_mse: 440.3783|  0:01:59s\n",
      "epoch 13 | loss: 410.82457| val_0_mse: 421.94452|  0:02:09s\n",
      "epoch 14 | loss: 394.54309| val_0_mse: 407.36658|  0:02:18s\n",
      "epoch 15 | loss: 389.97466| val_0_mse: 399.78754|  0:02:27s\n",
      "epoch 16 | loss: 371.6308| val_0_mse: 393.97153|  0:02:37s\n",
      "epoch 17 | loss: 416.98372| val_0_mse: 506.26199|  0:02:46s\n",
      "epoch 18 | loss: 394.61002| val_0_mse: 401.83945|  0:02:56s\n",
      "epoch 19 | loss: 410.65682| val_0_mse: 403.51682|  0:03:05s\n",
      "epoch 20 | loss: 374.32196| val_0_mse: 373.89532|  0:03:15s\n",
      "epoch 21 | loss: 392.19345| val_0_mse: 391.49673|  0:03:24s\n",
      "epoch 22 | loss: 408.49508| val_0_mse: 464.53415|  0:03:33s\n",
      "epoch 23 | loss: 377.82041| val_0_mse: 364.69077|  0:03:42s\n",
      "epoch 24 | loss: 387.86289| val_0_mse: 379.66171|  0:03:52s\n",
      "epoch 25 | loss: 387.04247| val_0_mse: 366.14124|  0:04:01s\n",
      "epoch 26 | loss: 376.86819| val_0_mse: 407.19916|  0:04:10s\n",
      "epoch 27 | loss: 385.38147| val_0_mse: 360.10345|  0:04:19s\n",
      "epoch 28 | loss: 380.195 | val_0_mse: 407.44629|  0:04:29s\n",
      "epoch 29 | loss: 364.49038| val_0_mse: 433.80765|  0:04:38s\n",
      "epoch 30 | loss: 378.38405| val_0_mse: 357.88416|  0:04:47s\n",
      "epoch 31 | loss: 371.70502| val_0_mse: 384.65848|  0:04:56s\n",
      "epoch 32 | loss: 365.6408| val_0_mse: 377.40012|  0:05:05s\n",
      "epoch 33 | loss: 374.77225| val_0_mse: 381.69382|  0:05:14s\n",
      "epoch 34 | loss: 369.39592| val_0_mse: 362.90225|  0:05:22s\n",
      "epoch 35 | loss: 357.57367| val_0_mse: 356.25983|  0:05:30s\n",
      "epoch 36 | loss: 363.64159| val_0_mse: 381.83673|  0:05:39s\n",
      "epoch 37 | loss: 367.46384| val_0_mse: 382.12137|  0:05:49s\n",
      "epoch 38 | loss: 353.57317| val_0_mse: 366.87762|  0:05:57s\n",
      "epoch 39 | loss: 370.13177| val_0_mse: 375.3757|  0:06:05s\n",
      "epoch 40 | loss: 344.66614| val_0_mse: 355.4303|  0:06:13s\n",
      "epoch 41 | loss: 346.33355| val_0_mse: 383.26221|  0:06:21s\n",
      "epoch 42 | loss: 343.39934| val_0_mse: 371.99704|  0:06:29s\n",
      "epoch 43 | loss: 345.81331| val_0_mse: 419.61832|  0:06:38s\n",
      "epoch 44 | loss: 375.41468| val_0_mse: 382.75632|  0:06:46s\n",
      "epoch 45 | loss: 341.49089| val_0_mse: 372.07343|  0:06:54s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 40 and best_val_0_mse = 355.4303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:29:22,030] Trial 5 finished with value: 355.4302978515625 and parameters: {'n_d': 40, 'n_a': 40, 'n_steps': 8, 'gamma': 1.0, 'lr': 0.026891952706879746}. Best is trial 5 with value: 355.4302978515625.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2778.90465| val_0_mse: 1142.24451|  0:00:04s\n",
      "epoch 1  | loss: 723.73489| val_0_mse: 649.52942|  0:00:08s\n",
      "epoch 2  | loss: 575.51865| val_0_mse: 521.01025|  0:00:13s\n",
      "epoch 3  | loss: 517.21333| val_0_mse: 494.89215|  0:00:17s\n",
      "epoch 4  | loss: 476.06268| val_0_mse: 515.79102|  0:00:21s\n",
      "epoch 5  | loss: 480.86153| val_0_mse: 453.3717|  0:00:26s\n",
      "epoch 6  | loss: 441.79941| val_0_mse: 489.62665|  0:00:30s\n",
      "epoch 7  | loss: 442.07282| val_0_mse: 497.72202|  0:00:34s\n",
      "epoch 8  | loss: 462.96424| val_0_mse: 417.20618|  0:00:38s\n",
      "epoch 9  | loss: 420.17854| val_0_mse: 471.72946|  0:00:42s\n",
      "epoch 10 | loss: 430.96485| val_0_mse: 426.53668|  0:00:47s\n",
      "epoch 11 | loss: 394.31121| val_0_mse: 462.05252|  0:00:51s\n",
      "epoch 12 | loss: 396.53768| val_0_mse: 556.7403|  0:00:55s\n",
      "epoch 13 | loss: 446.8497| val_0_mse: 428.43201|  0:00:59s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 8 and best_val_0_mse = 417.20618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:30:24,566] Trial 6 finished with value: 417.2061767578125 and parameters: {'n_d': 16, 'n_a': 24, 'n_steps': 5, 'gamma': 1.2, 'lr': 0.01111403744670877}. Best is trial 5 with value: 355.4302978515625.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3301.73281| val_0_mse: 2806.34668|  0:00:08s\n",
      "epoch 1  | loss: 2123.16954| val_0_mse: 1840.06189|  0:00:15s\n",
      "epoch 2  | loss: 1212.00059| val_0_mse: 976.52106|  0:00:23s\n",
      "epoch 3  | loss: 912.98403| val_0_mse: 857.25983|  0:00:31s\n",
      "epoch 4  | loss: 783.7884| val_0_mse: 699.85144|  0:00:39s\n",
      "epoch 5  | loss: 759.56213| val_0_mse: 652.78516|  0:00:46s\n",
      "epoch 6  | loss: 726.42919| val_0_mse: 782.90955|  0:00:54s\n",
      "epoch 7  | loss: 683.1117| val_0_mse: 579.61957|  0:01:02s\n",
      "epoch 8  | loss: 662.53058| val_0_mse: 563.26642|  0:01:10s\n",
      "epoch 9  | loss: 634.83762| val_0_mse: 546.2558|  0:01:17s\n",
      "epoch 10 | loss: 628.76118| val_0_mse: 643.66113|  0:01:25s\n",
      "epoch 11 | loss: 610.67539| val_0_mse: 530.86987|  0:01:34s\n",
      "epoch 12 | loss: 608.20062| val_0_mse: 578.35022|  0:01:42s\n",
      "epoch 13 | loss: 597.64037| val_0_mse: 767.56122|  0:01:50s\n",
      "epoch 14 | loss: 583.28756| val_0_mse: 578.40387|  0:01:58s\n",
      "epoch 15 | loss: 596.75074| val_0_mse: 510.97067|  0:02:06s\n",
      "epoch 16 | loss: 588.44041| val_0_mse: 558.53418|  0:02:14s\n",
      "epoch 17 | loss: 597.7433| val_0_mse: 544.40326|  0:02:22s\n",
      "epoch 18 | loss: 564.69401| val_0_mse: 554.88654|  0:02:30s\n",
      "epoch 19 | loss: 579.28975| val_0_mse: 586.04346|  0:02:38s\n",
      "epoch 20 | loss: 562.41507| val_0_mse: 589.89789|  0:02:46s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_0_mse = 510.97067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:33:15,525] Trial 7 finished with value: 510.9706726074219 and parameters: {'n_d': 32, 'n_a': 40, 'n_steps': 8, 'gamma': 1.4, 'lr': 0.002633364274386776}. Best is trial 5 with value: 355.4302978515625.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3516.67662| val_0_mse: 3342.29736|  0:00:09s\n",
      "epoch 1  | loss: 2767.89704| val_0_mse: 2609.90356|  0:00:18s\n",
      "epoch 2  | loss: 1797.35316| val_0_mse: 1625.34448|  0:00:27s\n",
      "epoch 3  | loss: 1096.65552| val_0_mse: 806.78345|  0:00:36s\n",
      "epoch 4  | loss: 810.74371| val_0_mse: 732.08844|  0:00:46s\n",
      "epoch 5  | loss: 714.5056| val_0_mse: 691.11877|  0:00:55s\n",
      "epoch 6  | loss: 669.38559| val_0_mse: 623.40686|  0:01:03s\n",
      "epoch 7  | loss: 649.15592| val_0_mse: 614.61584|  0:01:12s\n",
      "epoch 8  | loss: 607.06544| val_0_mse: 554.25574|  0:01:21s\n",
      "epoch 9  | loss: 590.94388| val_0_mse: 567.58307|  0:01:30s\n",
      "epoch 10 | loss: 576.34654| val_0_mse: 487.61182|  0:01:39s\n",
      "epoch 11 | loss: 583.08731| val_0_mse: 591.90814|  0:01:48s\n",
      "epoch 12 | loss: 555.951 | val_0_mse: 524.96082|  0:01:57s\n",
      "epoch 13 | loss: 557.52899| val_0_mse: 616.75006|  0:02:06s\n",
      "epoch 14 | loss: 551.92501| val_0_mse: 585.92877|  0:02:15s\n",
      "epoch 15 | loss: 550.82815| val_0_mse: 616.13672|  0:02:24s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 10 and best_val_0_mse = 487.61182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:35:45,263] Trial 8 finished with value: 487.61181640625 and parameters: {'n_d': 16, 'n_a': 56, 'n_steps': 9, 'gamma': 1.1, 'lr': 0.002258864077630223}. Best is trial 5 with value: 355.4302978515625.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2818.3166| val_0_mse: 1706.05579|  0:00:08s\n",
      "epoch 1  | loss: 1226.21111| val_0_mse: 949.25726|  0:00:17s\n",
      "epoch 2  | loss: 983.79427| val_0_mse: 1011.12268|  0:00:26s\n",
      "epoch 3  | loss: 883.8192| val_0_mse: 825.8913|  0:00:35s\n",
      "epoch 4  | loss: 783.52806| val_0_mse: 677.01062|  0:00:43s\n",
      "epoch 5  | loss: 789.22569| val_0_mse: 786.94672|  0:00:52s\n",
      "epoch 6  | loss: 751.13247| val_0_mse: 778.65912|  0:01:00s\n",
      "epoch 7  | loss: 781.05023| val_0_mse: 909.24091|  0:01:08s\n",
      "epoch 8  | loss: 792.98173| val_0_mse: 864.02148|  0:01:16s\n",
      "epoch 9  | loss: 796.16168| val_0_mse: 811.97693|  0:01:25s\n",
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_0_mse = 677.01062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:37:15,790] Trial 9 finished with value: 677.0106201171875 and parameters: {'n_d': 40, 'n_a': 8, 'n_steps': 10, 'gamma': 1.7000000000000002, 'lr': 0.00707325670454203}. Best is trial 5 with value: 355.4302978515625.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 905.78136| val_0_mse: 842.1593|  0:00:07s\n",
      "epoch 1  | loss: 576.96927| val_0_mse: 588.54529|  0:00:15s\n",
      "epoch 2  | loss: 534.54415| val_0_mse: 574.3125|  0:00:23s\n",
      "epoch 3  | loss: 509.45322| val_0_mse: 502.20798|  0:00:30s\n",
      "epoch 4  | loss: 482.06739| val_0_mse: 511.64062|  0:00:38s\n",
      "epoch 5  | loss: 477.54879| val_0_mse: 455.47827|  0:00:45s\n",
      "epoch 6  | loss: 454.18985| val_0_mse: 450.72784|  0:00:52s\n",
      "epoch 7  | loss: 464.21897| val_0_mse: 529.49817|  0:01:00s\n",
      "epoch 8  | loss: 452.56016| val_0_mse: 522.90625|  0:01:07s\n",
      "epoch 9  | loss: 464.46479| val_0_mse: 550.65198|  0:01:15s\n",
      "epoch 10 | loss: 471.93426| val_0_mse: 502.82108|  0:01:22s\n",
      "epoch 11 | loss: 438.92948| val_0_mse: 479.77469|  0:01:30s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 6 and best_val_0_mse = 450.72784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:38:50,112] Trial 10 finished with value: 450.72784423828125 and parameters: {'n_d': 64, 'n_a': 16, 'n_steps': 7, 'gamma': 1.0, 'lr': 0.09598194763981491}. Best is trial 5 with value: 355.4302978515625.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1386.17508| val_0_mse: 1252.40576|  0:00:07s\n",
      "epoch 1  | loss: 764.74697| val_0_mse: 659.52423|  0:00:14s\n",
      "epoch 2  | loss: 688.77505| val_0_mse: 627.98248|  0:00:21s\n",
      "epoch 3  | loss: 600.26935| val_0_mse: 717.33917|  0:00:28s\n",
      "epoch 4  | loss: 591.46567| val_0_mse: 608.31769|  0:00:35s\n",
      "epoch 5  | loss: 540.65097| val_0_mse: 519.87799|  0:00:42s\n",
      "epoch 6  | loss: 503.09061| val_0_mse: 478.02856|  0:00:49s\n",
      "epoch 7  | loss: 484.01526| val_0_mse: 558.59119|  0:00:55s\n",
      "epoch 8  | loss: 491.34765| val_0_mse: 612.5899|  0:01:02s\n",
      "epoch 9  | loss: 491.3473| val_0_mse: 479.06589|  0:01:09s\n",
      "epoch 10 | loss: 483.9198| val_0_mse: 504.69016|  0:01:15s\n",
      "epoch 11 | loss: 475.40656| val_0_mse: 435.04779|  0:01:22s\n",
      "epoch 12 | loss: 439.08586| val_0_mse: 516.21643|  0:01:29s\n",
      "epoch 13 | loss: 442.28771| val_0_mse: 509.36563|  0:01:36s\n",
      "epoch 14 | loss: 429.3283| val_0_mse: 477.11676|  0:01:43s\n",
      "epoch 15 | loss: 433.41556| val_0_mse: 482.4812|  0:01:50s\n",
      "epoch 16 | loss: 441.23335| val_0_mse: 465.96158|  0:01:57s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_0_mse = 435.04779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:40:50,989] Trial 11 finished with value: 435.04779052734375 and parameters: {'n_d': 56, 'n_a': 32, 'n_steps': 6, 'gamma': 1.6, 'lr': 0.025377981834921008}. Best is trial 5 with value: 355.4302978515625.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1411.58196| val_0_mse: 1019.84882|  0:00:07s\n",
      "epoch 1  | loss: 627.49407| val_0_mse: 733.58368|  0:00:15s\n",
      "epoch 2  | loss: 574.41656| val_0_mse: 599.76398|  0:00:23s\n",
      "epoch 3  | loss: 523.6163| val_0_mse: 512.37506|  0:00:31s\n",
      "epoch 4  | loss: 519.83493| val_0_mse: 506.39621|  0:00:39s\n",
      "epoch 5  | loss: 476.8182| val_0_mse: 569.08093|  0:00:47s\n",
      "epoch 6  | loss: 472.85906| val_0_mse: 448.31772|  0:00:54s\n",
      "epoch 7  | loss: 461.39451| val_0_mse: 493.134 |  0:01:02s\n",
      "epoch 8  | loss: 433.19372| val_0_mse: 401.12799|  0:01:10s\n",
      "epoch 9  | loss: 415.60395| val_0_mse: 442.91678|  0:01:18s\n",
      "epoch 10 | loss: 397.93559| val_0_mse: 443.44766|  0:01:26s\n",
      "epoch 11 | loss: 393.21287| val_0_mse: 391.6405|  0:01:34s\n",
      "epoch 12 | loss: 431.78567| val_0_mse: 515.58197|  0:01:41s\n",
      "epoch 13 | loss: 403.24926| val_0_mse: 382.35574|  0:01:49s\n",
      "epoch 14 | loss: 408.2173| val_0_mse: 446.76328|  0:01:57s\n",
      "epoch 15 | loss: 416.56166| val_0_mse: 427.92081|  0:02:05s\n",
      "epoch 16 | loss: 418.68832| val_0_mse: 429.95645|  0:02:13s\n",
      "epoch 17 | loss: 400.38485| val_0_mse: 404.98816|  0:02:21s\n",
      "epoch 18 | loss: 387.7912| val_0_mse: 381.3804|  0:02:29s\n",
      "epoch 19 | loss: 375.40735| val_0_mse: 362.15521|  0:02:37s\n",
      "epoch 20 | loss: 382.49668| val_0_mse: 370.93454|  0:02:45s\n",
      "epoch 21 | loss: 359.71208| val_0_mse: 403.91406|  0:02:52s\n",
      "epoch 22 | loss: 379.62967| val_0_mse: 418.07733|  0:03:00s\n",
      "epoch 23 | loss: 379.32688| val_0_mse: 394.21875|  0:03:08s\n",
      "epoch 24 | loss: 366.00573| val_0_mse: 385.94699|  0:03:16s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 19 and best_val_0_mse = 362.15521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:44:11,494] Trial 12 finished with value: 362.15521240234375 and parameters: {'n_d': 40, 'n_a': 48, 'n_steps': 7, 'gamma': 1.0, 'lr': 0.0195932166254528}. Best is trial 5 with value: 355.4302978515625.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1050.25865| val_0_mse: 928.78296|  0:00:10s\n",
      "epoch 1  | loss: 615.14411| val_0_mse: 686.92407|  0:00:19s\n",
      "epoch 2  | loss: 567.98927| val_0_mse: 513.16003|  0:00:29s\n",
      "epoch 3  | loss: 511.42272| val_0_mse: 459.81396|  0:00:39s\n",
      "epoch 4  | loss: 466.97601| val_0_mse: 507.00708|  0:00:49s\n",
      "epoch 5  | loss: 452.10976| val_0_mse: 460.92276|  0:00:58s\n",
      "epoch 6  | loss: 445.30468| val_0_mse: 435.74915|  0:01:08s\n",
      "epoch 7  | loss: 462.34578| val_0_mse: 482.58368|  0:01:18s\n",
      "epoch 8  | loss: 442.99218| val_0_mse: 494.02258|  0:01:28s\n",
      "epoch 9  | loss: 424.24988| val_0_mse: 463.80392|  0:01:38s\n",
      "epoch 10 | loss: 418.65861| val_0_mse: 520.65222|  0:01:47s\n",
      "epoch 11 | loss: 420.74755| val_0_mse: 455.95706|  0:01:57s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 6 and best_val_0_mse = 435.74915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:46:14,172] Trial 13 finished with value: 435.7491455078125 and parameters: {'n_d': 40, 'n_a': 56, 'n_steps': 8, 'gamma': 1.0, 'lr': 0.02457570931258628}. Best is trial 5 with value: 355.4302978515625.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 892.31883| val_0_mse: 1274.37329|  0:00:08s\n",
      "epoch 1  | loss: 580.95369| val_0_mse: 631.85681|  0:00:16s\n",
      "epoch 2  | loss: 538.21748| val_0_mse: 610.10193|  0:00:25s\n",
      "epoch 3  | loss: 585.16131| val_0_mse: 609.31921|  0:00:34s\n",
      "epoch 4  | loss: 575.28207| val_0_mse: 531.09082|  0:00:42s\n",
      "epoch 5  | loss: 555.55892| val_0_mse: 553.24854|  0:00:51s\n",
      "epoch 6  | loss: 526.27635| val_0_mse: 502.36099|  0:00:59s\n",
      "epoch 7  | loss: 508.05677| val_0_mse: 548.49426|  0:01:08s\n",
      "epoch 8  | loss: 487.58393| val_0_mse: 519.9632|  0:01:16s\n",
      "epoch 9  | loss: 491.5156| val_0_mse: 509.70877|  0:01:24s\n",
      "epoch 10 | loss: 520.16899| val_0_mse: 591.38385|  0:01:33s\n",
      "epoch 11 | loss: 493.51304| val_0_mse: 479.21945|  0:01:41s\n",
      "epoch 12 | loss: 500.66278| val_0_mse: 479.50894|  0:01:50s\n",
      "epoch 13 | loss: 459.16815| val_0_mse: 466.34528|  0:01:59s\n",
      "epoch 14 | loss: 468.53426| val_0_mse: 495.14215|  0:02:07s\n",
      "epoch 15 | loss: 462.01216| val_0_mse: 488.89127|  0:02:16s\n",
      "epoch 16 | loss: 456.43572| val_0_mse: 522.1615|  0:02:24s\n",
      "epoch 17 | loss: 464.2735| val_0_mse: 480.44525|  0:02:33s\n",
      "epoch 18 | loss: 453.08731| val_0_mse: 498.9314|  0:02:42s\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 13 and best_val_0_mse = 466.34528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-08-29 17:49:00,869] Trial 14 finished with value: 466.34527587890625 and parameters: {'n_d': 32, 'n_a': 48, 'n_steps': 8, 'gamma': 1.1, 'lr': 0.08205226208593713}. Best is trial 5 with value: 355.4302978515625.\n",
      "C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-3, 1e-1)\n",
      "f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3578.84203| val_0_mse: 3403.96729|  0:00:07s\n",
      "epoch 1  | loss: 3012.77328| val_0_mse: 3037.44678|  0:00:14s\n",
      "epoch 2  | loss: 2571.23486| val_0_mse: 2659.6748|  0:00:22s\n",
      "epoch 3  | loss: 2211.8852| val_0_mse: 2233.02979|  0:00:31s\n",
      "epoch 4  | loss: 1922.14314| val_0_mse: 1923.6792|  0:00:40s\n",
      "epoch 5  | loss: 1641.06424| val_0_mse: 1774.36646|  0:00:48s\n",
      "epoch 6  | loss: 1416.66305| val_0_mse: 1462.95081|  0:00:56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-08-29 17:50:03,278] Trial 15 failed with parameters: {'n_d': 48, 'n_a': 32, 'n_steps': 7, 'gamma': 1.5, 'lr': 0.001059609576931035} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hayka\\AppData\\Local\\Temp\\ipykernel_11476\\2357511221.py\", line 26, in objective\n",
      "    model.fit(\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 258, in fit\n",
      "    self._train_epoch(train_dataloader)\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 489, in _train_epoch\n",
      "    batch_logs = self._train_batch(X, y)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 527, in _train_batch\n",
      "    output, M_loss = self.network(X)\n",
      "                     ^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 616, in forward\n",
      "    return self.tabnet(x)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 492, in forward\n",
      "    steps_output, M_loss = self.encoder(x)\n",
      "                           ^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 181, in forward\n",
      "    out = self.feat_transformers[step](masked_x)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 737, in forward\n",
      "    x = self.shared(x)\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 780, in forward\n",
      "    x = torch.add(x, self.glu_layers[glu_id](x))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 804, in forward\n",
      "    x = self.bn(x)\n",
      "        ^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 36, in forward\n",
      "    res = [self.bn(x_) for x_ in chunks]\n",
      "           ^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\", line 193, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"f:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py\", line 2817, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-29 17:50:03,282] Trial 15 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest RMSE:\u001b[39m\u001b[33m\"\u001b[39m, study.best_value)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest hyperparameters:\u001b[39m\u001b[33m\"\u001b[39m, study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     14\u001b[39m lr = trial.suggest_loguniform(\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1e-3\u001b[39m, \u001b[32m1e-1\u001b[39m)\n\u001b[32m     16\u001b[39m model = TabNetRegressor(\n\u001b[32m     17\u001b[39m     n_d=n_d,\n\u001b[32m     18\u001b[39m     n_a=n_a,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     mask_type=\u001b[33m\"\u001b[39m\u001b[33mentmax\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvirtual_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\n\u001b[32m     33\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m y_pred = model.predict(X_val_np)\n\u001b[32m     36\u001b[39m mse = mean_squared_error(y_val_np, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:258\u001b[39m, in \u001b[36mTabModel.fit\u001b[39m\u001b[34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_epochs):\n\u001b[32m    254\u001b[39m \n\u001b[32m    255\u001b[39m     \u001b[38;5;66;03m# Call method on_epoch_begin for all callbacks\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28mself\u001b[39m._callback_container.on_epoch_begin(epoch_idx)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m     \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:489\u001b[39m, in \u001b[36mTabModel._train_epoch\u001b[39m\u001b[34m(self, train_loader)\u001b[39m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m    487\u001b[39m     \u001b[38;5;28mself\u001b[39m._callback_container.on_batch_begin(batch_idx)\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     batch_logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m     \u001b[38;5;28mself\u001b[39m._callback_container.on_batch_end(batch_idx, batch_logs)\n\u001b[32m    493\u001b[39m epoch_logs = {\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._optimizer.param_groups[-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:527\u001b[39m, in \u001b[36mTabModel._train_batch\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.network.parameters():\n\u001b[32m    525\u001b[39m     param.grad = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m output, M_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.compute_loss(output, y)\n\u001b[32m    530\u001b[39m \u001b[38;5;66;03m# Add the overall sparsity loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:616\u001b[39m, in \u001b[36mTabNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    615\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.embedder(x)\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtabnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:492\u001b[39m, in \u001b[36mTabNetNoEmbeddings.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    491\u001b[39m     res = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     steps_output, M_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     res = torch.sum(torch.stack(steps_output, dim=\u001b[32m0\u001b[39m), dim=\u001b[32m0\u001b[39m)\n\u001b[32m    495\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_multi_task:\n\u001b[32m    496\u001b[39m         \u001b[38;5;66;03m# Result will be in list format\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:181\u001b[39m, in \u001b[36mTabNetEncoder.forward\u001b[39m\u001b[34m(self, x, prior)\u001b[39m\n\u001b[32m    179\u001b[39m M_feature_level = torch.matmul(M, \u001b[38;5;28mself\u001b[39m.group_attention_matrix)\n\u001b[32m    180\u001b[39m masked_x = torch.mul(M_feature_level, x)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeat_transformers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m d = ReLU()(out[:, : \u001b[38;5;28mself\u001b[39m.n_d])\n\u001b[32m    183\u001b[39m steps_output.append(d)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:737\u001b[39m, in \u001b[36mFeatTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m737\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshared\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    738\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.specifics(x)\n\u001b[32m    739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:780\u001b[39m, in \u001b[36mGLU_Block.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    777\u001b[39m     layers_left = \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_glu)\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m glu_id \u001b[38;5;129;01min\u001b[39;00m layers_left:\n\u001b[32m--> \u001b[39m\u001b[32m780\u001b[39m     x = torch.add(x, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mglu_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mglu_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    781\u001b[39m     x = x * scale\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:804\u001b[39m, in \u001b[36mGLU_Layer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    803\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.fc(x)\n\u001b[32m--> \u001b[39m\u001b[32m804\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m     out = torch.mul(x[:, : \u001b[38;5;28mself\u001b[39m.output_dim], torch.sigmoid(x[:, \u001b[38;5;28mself\u001b[39m.output_dim :]))\n\u001b[32m    806\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:36\u001b[39m, in \u001b[36mGBN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     35\u001b[39m     chunks = x.chunk(\u001b[38;5;28mint\u001b[39m(np.ceil(x.shape[\u001b[32m0\u001b[39m] / \u001b[38;5;28mself\u001b[39m.virtual_batch_size)), \u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     res = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(res, dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    186\u001b[39m     bn_training = (\u001b[38;5;28mself\u001b[39m.running_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.running_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_mean\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:2817\u001b[39m, in \u001b[36mbatch_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[39m\n\u001b[32m   2814\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m   2815\u001b[39m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m-> \u001b[39m\u001b[32m2817\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2818\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2820\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2821\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2822\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-29T12:17:29.518384Z",
     "iopub.status.busy": "2025-08-29T12:17:29.518025Z",
     "iopub.status.idle": "2025-08-29T12:19:05.148261Z",
     "shell.execute_reply": "2025-08-29T12:19:05.146763Z",
     "shell.execute_reply.started": "2025-08-29T12:17:29.518358Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T12:28:05.612767Z",
     "iopub.status.busy": "2025-08-29T12:28:05.612378Z",
     "iopub.status.idle": "2025-08-29T12:28:06.172293Z",
     "shell.execute_reply": "2025-08-29T12:28:06.171312Z",
     "shell.execute_reply.started": "2025-08-29T12:28:05.612738Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model Validation MSE: 466.3453\n",
      "Loaded model Validation RMSE: 21.5950\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Kaydedilen en iyi modeli yükle\n",
    "best_model = joblib.load(\"best_tabnet_model.pkl\")\n",
    "\n",
    "# Validation seti üzerinde tahmin\n",
    "y_pred_val_loaded = best_model.predict(X_val_np)\n",
    "\n",
    "# RMSE hesapla\n",
    "mse_loaded = mean_squared_error(y_val_np, y_pred_val_loaded)\n",
    "rmse_loaded = np.sqrt(mse_loaded)\n",
    "\n",
    "print(f\"Loaded model Validation MSE: {mse_loaded:.4f}\")\n",
    "print(f\"Loaded model Validation RMSE: {rmse_loaded:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62951 entries, 0 to 62950\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   event_time    62951 non-null  object\n",
      " 1   event_type    62951 non-null  object\n",
      " 2   product_id    62951 non-null  object\n",
      " 3   category_id   62951 non-null  object\n",
      " 4   user_id       62951 non-null  object\n",
      " 5   user_session  62951 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-28 10:09:58+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_015000</td>\n",
       "      <td>CAT_00019</td>\n",
       "      <td>USER_109759</td>\n",
       "      <td>SESSION_164059</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-06-25 11:57:50+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_023887</td>\n",
       "      <td>CAT_00010</td>\n",
       "      <td>USER_010614</td>\n",
       "      <td>SESSION_109583</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-30 14:34:20+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_022673</td>\n",
       "      <td>CAT_00090</td>\n",
       "      <td>USER_041338</td>\n",
       "      <td>SESSION_171382</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06-30 22:12:18+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_004664</td>\n",
       "      <td>CAT_00280</td>\n",
       "      <td>USER_015376</td>\n",
       "      <td>SESSION_137110</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-26 16:55:18+00:00</td>\n",
       "      <td>ADD_CART</td>\n",
       "      <td>PROD_027815</td>\n",
       "      <td>CAT_00027</td>\n",
       "      <td>USER_054449</td>\n",
       "      <td>SESSION_146503</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 event_time event_type   product_id category_id      user_id  \\\n",
       "0 2025-06-28 10:09:58+00:00   ADD_CART  PROD_015000   CAT_00019  USER_109759   \n",
       "1 2025-06-25 11:57:50+00:00   ADD_CART  PROD_023887   CAT_00010  USER_010614   \n",
       "2 2025-06-30 14:34:20+00:00   ADD_CART  PROD_022673   CAT_00090  USER_041338   \n",
       "3 2025-06-30 22:12:18+00:00   ADD_CART  PROD_004664   CAT_00280  USER_015376   \n",
       "4 2025-06-26 16:55:18+00:00   ADD_CART  PROD_027815   CAT_00027  USER_054449   \n",
       "\n",
       "     user_session  hour  dayofweek  \n",
       "0  SESSION_164059    10          5  \n",
       "1  SESSION_109583    11          2  \n",
       "2  SESSION_171382    14          0  \n",
       "3  SESSION_137110    22          0  \n",
       "4  SESSION_146503    16          3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test verisini yükleme\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# Genel bilgi\n",
    "print(test.info())\n",
    "# Test verisine datetime özelliklerini ekleyelim\n",
    "test[\"event_time\"] = pd.to_datetime(test[\"event_time\"])\n",
    "test[\"hour\"] = test[\"event_time\"].dt.hour\n",
    "test[\"dayofweek\"] = test[\"event_time\"].dt.dayofweek\n",
    "\n",
    "# İlk birkaç satır\n",
    "display(test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "def build_session_features_test_rowlevel(df):\n",
    "    # --- Oturum bazlı özetleri hesapla ---\n",
    "    session_feats = df.groupby(\"user_session\").agg(\n",
    "        event_count=(\"event_type\", \"count\"),\n",
    "        unique_products=(\"product_id\", \"nunique\"),\n",
    "        unique_categories=(\"category_id\", \"nunique\"),\n",
    "        unique_event_types=(\"event_type\", \"nunique\"),\n",
    "        avg_hour=(\"hour\", \"mean\"),\n",
    "        dayofweek_mode=(\"dayofweek\", lambda x: x.mode().iloc[0] if not x.mode().empty else -1),\n",
    "    ).reset_index()\n",
    "\n",
    "    # --- Session length ---\n",
    "    df_time = df[[\"user_session\", \"event_time\"]].copy()\n",
    "    df_time[\"event_time\"] = pd.to_datetime(df_time[\"event_time\"])\n",
    "    session_length = df_time.groupby(\"user_session\").agg(\n",
    "        session_length=(\"event_time\", lambda x: (x.max() - x.min()).total_seconds())\n",
    "    ).reset_index()\n",
    "    session_feats = session_feats.merge(session_length, on=\"user_session\", how=\"left\")\n",
    "\n",
    "    # --- Event type counts ---\n",
    "    event_counts = df.groupby([\"user_session\", \"event_type\"]).size().unstack(fill_value=0).reset_index()\n",
    "    session_feats = session_feats.merge(event_counts, on=\"user_session\", how=\"left\")\n",
    "\n",
    "    # --- Ratios ve ek özellikler ---\n",
    "    for ev in [\"ADD_CART\", \"VIEW\", \"REMOVE_CART\", \"PURCHASE\"]:\n",
    "        if ev in session_feats.columns:\n",
    "            session_feats[f\"ratio_{ev}\"] = session_feats[ev] / session_feats[\"event_count\"]\n",
    "\n",
    "    session_feats[\"product_diversity\"] = session_feats[\"unique_products\"] / session_feats[\"event_count\"]\n",
    "    session_feats[\"category_diversity\"] = session_feats[\"unique_categories\"] / session_feats[\"event_count\"]\n",
    "    session_feats[\"events_per_unique_product\"] = session_feats[\"event_count\"] / session_feats[\"unique_products\"]\n",
    "    session_feats[\"view_per_product\"] = session_feats.get(\"VIEW\", 0) / session_feats[\"unique_products\"]\n",
    "    session_feats[\"addcart_per_product\"] = session_feats.get(\"ADD_CART\", 0) / session_feats[\"unique_products\"]\n",
    "    session_feats[\"purchase_per_product\"] = session_feats.get(\"PURCHASE\", 0) / session_feats[\"unique_products\"]\n",
    "    session_feats[\"category_per_product\"] = session_feats[\"unique_categories\"] / session_feats[\"unique_products\"]\n",
    "    session_feats[\"session_length_log\"] = np.log1p(session_feats[\"session_length\"])\n",
    "\n",
    "    # --- Cyclical encoding ---\n",
    "    session_feats[\"hour_sin\"] = np.sin(2 * np.pi * session_feats[\"avg_hour\"] / 24)\n",
    "    session_feats[\"hour_cos\"] = np.cos(2 * np.pi * session_feats[\"avg_hour\"] / 24)\n",
    "    session_feats[\"dayofweek_sin\"] = np.sin(2 * np.pi * session_feats[\"dayofweek_mode\"] / 7)\n",
    "    session_feats[\"dayofweek_cos\"] = np.cos(2 * np.pi * session_feats[\"dayofweek_mode\"] / 7)\n",
    "\n",
    "    # --- Numeric encoding ---\n",
    "    for col in [\"product_id\", \"category_id\", \"user_id\"]:\n",
    "        if df[col].dtype.name != \"category\":\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "        session_stats = df.groupby(\"user_session\")[col].apply(lambda x: x.cat.codes.mean()).reset_index(name=f\"{col}_mean_code\")\n",
    "        session_feats = session_feats.merge(session_stats, on=\"user_session\", how=\"left\")\n",
    "\n",
    "    # --- Oturum özetlerini her satıra kopyala ---\n",
    "    df_rowlevel = df.merge(session_feats, on=\"user_session\", how=\"left\")\n",
    "    \n",
    "    return df_rowlevel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission kaydedildi: submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_session</th>\n",
       "      <th>session_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SESSION_000000</td>\n",
       "      <td>264.517395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SESSION_000013</td>\n",
       "      <td>16.970219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SESSION_000022</td>\n",
       "      <td>40.910393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SESSION_000024</td>\n",
       "      <td>23.617821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SESSION_000025</td>\n",
       "      <td>35.236328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_session  session_value\n",
       "0  SESSION_000000     264.517395\n",
       "1  SESSION_000013      16.970219\n",
       "2  SESSION_000022      40.910393\n",
       "3  SESSION_000024      23.617821\n",
       "4  SESSION_000025      35.236328"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [code]\n",
    "# 1️⃣ Test dataframe’ini row-level ve oturum özetleriyle hazırla\n",
    "test_rowlevel = build_session_features_test_rowlevel(test)\n",
    "\n",
    "# X_train: eğitim sırasında kullanılan dataframe\n",
    "# test_rowlevel: test dataframe row-level feature’ları\n",
    "\n",
    "# 1️⃣ Feature hizalama\n",
    "X_test_aligned = test_rowlevel[X_train.columns.intersection(test_rowlevel.columns)].copy()\n",
    "\n",
    "# 2️⃣ Eksik kolonları sıfır ile ekle\n",
    "for col in X_train.columns:\n",
    "    if col not in X_test_aligned.columns:\n",
    "        X_test_aligned[col] = 0\n",
    "\n",
    "# 3️⃣ Sütun sırasını eğitimle aynı yap\n",
    "X_test_aligned = X_test_aligned[X_train.columns]\n",
    "\n",
    "# 4️⃣ NumPy array'e çevir\n",
    "X_test_np = X_test_aligned.values.astype(np.float32)\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "# 3️⃣ TabNet ile tahmin\n",
    "y_pred_test = best_model.predict(X_test_np).flatten()\n",
    "\n",
    "test['pred'] = y_pred_test\n",
    "y_pred_session = test.groupby('user_session')['pred'].mean().reset_index()\n",
    "\n",
    "\n",
    "# 4️⃣ Submission dosyasını oluştur ve kaydet\n",
    "submission = y_pred_session.rename(columns={'pred': 'session_value'})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission kaydedildi: submission.csv\")\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13341508,
     "sourceId": 112016,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
